{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPARK_HOME = /root/uni-projects/bdm2/.venv/lib/python3.10/site-packages/pyspark\n",
      "JAVA_HOME = /root/.sdkman/candidates/java/current\n",
      "PATH = /root/uni-projects/bdm2/.venv/lib/python3.10/site-packages/pyspark/bin:/root/uni-projects/bdm2/.venv/lib/python3.10/site-packages/pyspark/bin:/root/uni-projects/bdm2/.venv/bin:/root/.vscode-server/bin/dc96b837cf6bb4af9cd736aa3af08cf8279f7685/bin/remote-cli:/root/.tfenv/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/lib/wsl/lib:/mnt/c/Users/Akos Schneider/.jdks/oracle-8/bin:/mnt/c/Program Files/Common Files/Oracle/Java/javapath:/mnt/c/Program Files (x86)/Common Files/Oracle/Java/javapath:/mnt/c/WINDOWS/system32:/mnt/c/WINDOWS:/mnt/c/WINDOWS/System32/Wbem:/mnt/c/WINDOWS/System32/WindowsPowerShell/v1.0/:/mnt/c/WINDOWS/System32/OpenSSH/:/mnt/c/Program Files (x86)/NVIDIA Corporation/PhysX/Common:/mnt/c/Program Files/Git/cmd:/mnt/c/Program Files/TortoiseGit/bin:/mnt/c/Users/Akos Schneider/apache-maven-3.8.6/bin:/mnt/c/Program Files/nodejs/:/mnt/c/ProgramData/chocolatey/bin:/mnt/c/Users/Akos Schneider/terraform-1.3.4:/mnt/c/Users/Akos Schneider/.tfenv/bin:/mnt/c/WINDOWS/system32:/mnt/c/WINDOWS:/mnt/c/WINDOWS/System32/Wbem:/mnt/c/WINDOWS/System32/WindowsPowerShell/v1.0/:/mnt/c/WINDOWS/System32/OpenSSH/:/mnt/c/Program Files/NVIDIA Corporation/NVIDIA NvDLISR:/mnt/c/Users/Akos Schneider/.pyenv/pyenv-win/bin:/mnt/c/Users/Akos Schneider/.pyenv/pyenv-win/shims:/mnt/c/Users/Akos Schneider/anaconda3/Library/bin:/mnt/c/Users/Akos Schneider/anaconda3/Scripts:/mnt/c/Users/Akos Schneider/anaconda3/condabin:/mnt/c/Program Files/Cloudflare/Cloudflare WARP/:/mnt/c/Gradle/gradle-8.3-bin/gradle-8.3/bin:/mnt/c/Users/Akos Schneider/.pyenv/pyenv-win/versions/3.10.11/Scripts:/mnt/c/Program Files/PuTTY/:/Docker/host/bin:/mnt/c/hadoop/hadoop-3.3.6/bin:/mnt/c/Users/Akos Schneider/mongosh/mongosh-2.2.5-win32-x64/bin:/mnt/c/Users/Akos Schneider/.pyenv/pyenv-win/bin:/mnt/c/Users/Akos Schneider/.pyenv/pyenv-win/shims:/mnt/c/Users/Akos Schneider/AppData/Local/Microsoft/WindowsApps:/mnt/c/Users/Akos Schneider/AppData/Roaming/npm:/mnt/c/Users/Akos Schneider/AppData/Local/Google/Cloud SDK/google-cloud-sdk/bin:/mnt/c/Users/Akos Schneider/AppData/Local/Programs/Microsoft VS Code/bin:/mnt/c/Users/Akos Schneider/AppData/Local/Pandoc/:/mnt/c/Users/Akos Schneider/AppData/Local/JetBrains/Toolbox/scripts:/mnt/c/Users/Akos Schneider/AppData/Local/GitHubDesktop/bin:/mnt/c/Users/Akos Schneider/AppData/Roaming/TinyTeX/bin/windows:/mnt/c/Users/Akos Schneider/AppData/Local/Programs/mongosh/:/snap/bin\n",
      "PYSPARK_PYTHON = /root/uni-projects/bdm2/.venv/bin/python\n",
      "PYSPARK_DRIVER_PYTHON = /root/uni-projects/bdm2/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "from utils import validate_env, setup_env, print_env\n",
    "import os\n",
    "import sys\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "setup_env()\n",
    "validate_env()\n",
    "print_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "24/05/12 17:21:52 WARN Utils: Your hostname, akos-sch resolves to a loopback address: 127.0.1.1; using 172.23.175.226 instead (on interface eth0)\n",
      "24/05/12 17:21:52 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/root/uni-projects/bdm2/.venv/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.apache.spark#spark-avro_2.12 added as a dependency\n",
      "org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-82c4fc72-ddaf-4061-a781-f392f4ca4ead;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-avro_2.12;3.5.1 in central\n",
      "\tfound org.tukaani#xz;1.9 in central\n",
      "\tfound org.mongodb.spark#mongo-spark-connector_2.12;10.3.0 in central\n",
      "\tfound org.mongodb#mongodb-driver-sync;4.8.2 in central\n",
      "\t[4.8.2] org.mongodb#mongodb-driver-sync;[4.8.1,4.8.99)\n",
      "\tfound org.mongodb#bson;4.8.2 in central\n",
      "\tfound org.mongodb#mongodb-driver-core;4.8.2 in central\n",
      "\tfound org.mongodb#bson-record-codec;4.8.2 in central\n",
      ":: resolution report :: resolve 1955ms :: artifacts dl 10ms\n",
      "\t:: modules in use:\n",
      "\torg.apache.spark#spark-avro_2.12;3.5.1 from central in [default]\n",
      "\torg.mongodb#bson;4.8.2 from central in [default]\n",
      "\torg.mongodb#bson-record-codec;4.8.2 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-core;4.8.2 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-sync;4.8.2 from central in [default]\n",
      "\torg.mongodb.spark#mongo-spark-connector_2.12;10.3.0 from central in [default]\n",
      "\torg.tukaani#xz;1.9 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   7   |   1   |   0   |   0   ||   7   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-82c4fc72-ddaf-4061-a781-f392f4ca4ead\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 7 already retrieved (0kB/6ms)\n",
      "24/05/12 17:21:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version = 3.10\n",
      "Spark version = 3.5.1\n",
      "[('spark.master', 'local'), ('spark.driver.extraJavaOptions', '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false'), ('spark.app.id', 'local-1715527315445'), ('spark.app.initial.jar.urls', 'spark://172.23.175.226:44433/jars/org.tukaani_xz-1.9.jar,spark://172.23.175.226:44433/jars/org.mongodb_mongodb-driver-core-4.8.2.jar,spark://172.23.175.226:44433/jars/org.mongodb.spark_mongo-spark-connector_2.12-10.3.0.jar,spark://172.23.175.226:44433/jars/org.mongodb_bson-record-codec-4.8.2.jar,spark://172.23.175.226:44433/jars/org.apache.spark_spark-avro_2.12-3.5.1.jar,spark://172.23.175.226:44433/jars/org.mongodb_mongodb-driver-sync-4.8.2.jar,spark://172.23.175.226:44433/jars/org.mongodb_bson-4.8.2.jar'), ('spark.submit.pyFiles', '/root/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.1.jar,/root/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-10.3.0.jar,/root/.ivy2/jars/org.tukaani_xz-1.9.jar,/root/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.8.2.jar,/root/.ivy2/jars/org.mongodb_bson-4.8.2.jar,/root/.ivy2/jars/org.mongodb_mongodb-driver-core-4.8.2.jar,/root/.ivy2/jars/org.mongodb_bson-record-codec-4.8.2.jar'), ('spark.files', 'file:///root/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.1.jar,file:///root/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-10.3.0.jar,file:///root/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///root/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.8.2.jar,file:///root/.ivy2/jars/org.mongodb_bson-4.8.2.jar,file:///root/.ivy2/jars/org.mongodb_mongodb-driver-core-4.8.2.jar,file:///root/.ivy2/jars/org.mongodb_bson-record-codec-4.8.2.jar'), ('spark.executor.id', 'driver'), ('spark.mongodb.write.connection.uri', 'mongodb://127.0.0.1:27017/'), ('spark.repl.local.jars', 'file:///root/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.1.jar,file:///root/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-10.3.0.jar,file:///root/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///root/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.8.2.jar,file:///root/.ivy2/jars/org.mongodb_bson-4.8.2.jar,file:///root/.ivy2/jars/org.mongodb_mongodb-driver-core-4.8.2.jar,file:///root/.ivy2/jars/org.mongodb_bson-record-codec-4.8.2.jar'), ('spark.app.initial.file.urls', 'file:///root/.ivy2/jars/org.mongodb_bson-record-codec-4.8.2.jar,file:///root/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.8.2.jar,file:///root/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-10.3.0.jar,file:///root/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.1.jar,file:///root/.ivy2/jars/org.mongodb_bson-4.8.2.jar,file:///root/.ivy2/jars/org.mongodb_mongodb-driver-core-4.8.2.jar,file:///root/.ivy2/jars/org.tukaani_xz-1.9.jar'), ('spark.rdd.compress', 'True'), ('spark.app.startTime', '1715527314848'), ('spark.driver.host', '172.23.175.226'), ('spark.executor.extraJavaOptions', '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false'), ('spark.mongodb.read.connection.uri', 'mongodb://127.0.0.1:27017/'), ('spark.serializer.objectStreamReset', '100'), ('spark.app.submitTime', '1715527314750'), ('spark.jars', 'file:///root/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.1.jar,file:///root/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-10.3.0.jar,file:///root/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///root/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.8.2.jar,file:///root/.ivy2/jars/org.mongodb_bson-4.8.2.jar,file:///root/.ivy2/jars/org.mongodb_mongodb-driver-core-4.8.2.jar,file:///root/.ivy2/jars/org.mongodb_bson-record-codec-4.8.2.jar'), ('spark.app.name', 'Spark Dataframes Tutorial'), ('spark.submit.deployMode', 'client'), ('spark.jars.packages', 'org.apache.spark:spark-avro_2.12:3.5.1,org.mongodb.spark:mongo-spark-connector_2.12:10.3.0'), ('spark.ui.showConsoleProgress', 'true'), ('spark.driver.port', '44433')]\n"
     ]
    }
   ],
   "source": [
    "if spark:\n",
    "    spark.stop()\n",
    "# Create the configuration in the local machine and give a name to the application\n",
    "conf = SparkConf() \\\n",
    "    .set(\"spark.master\", \"local\") \\\n",
    "    .set(\"spark.app.name\", \"Spark Dataframes Tutorial\") \\\n",
    "    .set(\"spark.jars.packages\", \"org.apache.spark:spark-avro_2.12:3.5.1,org.mongodb.spark:mongo-spark-connector_2.12:10.3.0\")\n",
    "\n",
    "\n",
    "# Create the session \n",
    "spark = SparkSession.builder \\\n",
    "    .config(conf=conf) \\\n",
    "    .config(\"spark.mongodb.read.connection.uri\", \"mongodb://127.0.0.1:27017/\") \\\n",
    "    .config(\"spark.mongodb.write.connection.uri\", \"mongodb://127.0.0.1:27017/\") \\\n",
    "    .getOrCreate()\n",
    "print(f\"Python version = {spark.sparkContext.pythonVer}\")\n",
    "print(f\"Spark version = {spark.version}\")\n",
    "print(spark.sparkContext.getConf().getAll())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "root\n",
      " |-- nom_cabina: string (nullable = true)\n",
      " |-- codi_dtes: string (nullable = true)\n",
      " |-- zqa: integer (nullable = true)\n",
      " |-- codi_eoi: integer (nullable = true)\n",
      " |-- longitud: double (nullable = true)\n",
      " |-- latitud: double (nullable = true)\n",
      " |-- Ubicacio: string (nullable = true)\n",
      " |-- Codi_Districte: integer (nullable = true)\n",
      " |-- Nom_Districte: string (nullable = true)\n",
      " |-- Codi_Barri: integer (nullable = true)\n",
      " |-- Nom_Barri: string (nullable = true)\n",
      " |-- Ocupacio_sol: string (nullable = true)\n",
      " |-- Emissions_Properes: string (nullable = true)\n",
      " |-- Contaminant_1: string (nullable = true)\n",
      " |-- Contaminant_2: string (nullable = true)\n",
      " |-- Contaminant_3: string (nullable = true)\n",
      "\n",
      "39\n",
      "root\n",
      " |-- Estacio: integer (nullable = true)\n",
      " |-- nom_cabina: string (nullable = true)\n",
      " |-- codi_dtes: string (nullable = true)\n",
      " |-- zqa: integer (nullable = true)\n",
      " |-- codi_eoi: integer (nullable = true)\n",
      " |-- Longitud: double (nullable = true)\n",
      " |-- Latitud: double (nullable = true)\n",
      " |-- ubicacio: string (nullable = true)\n",
      " |-- Codi_districte: integer (nullable = true)\n",
      " |-- Nom_districte: string (nullable = true)\n",
      " |-- Codi_barri: integer (nullable = true)\n",
      " |-- Nom_barri: string (nullable = true)\n",
      " |-- Clas_1: string (nullable = true)\n",
      " |-- Clas_2: string (nullable = true)\n",
      " |-- Codi_Contaminant: integer (nullable = true)\n",
      "\n",
      "50\n",
      "root\n",
      " |-- Estacio: integer (nullable = true)\n",
      " |-- nom_cabina: string (nullable = true)\n",
      " |-- codi_dtes: string (nullable = true)\n",
      " |-- zqa: integer (nullable = true)\n",
      " |-- codi_eoi: integer (nullable = true)\n",
      " |-- Longitud: double (nullable = true)\n",
      " |-- Latitud: double (nullable = true)\n",
      " |-- ubicacio: string (nullable = true)\n",
      " |-- Codi_districte: integer (nullable = true)\n",
      " |-- Nom_districte: string (nullable = true)\n",
      " |-- Codi_barri: integer (nullable = true)\n",
      " |-- Nom_barri: string (nullable = true)\n",
      " |-- Clas_1: string (nullable = true)\n",
      " |-- Clas_2: string (nullable = true)\n",
      " |-- Codi_Contaminant: integer (nullable = true)\n",
      "\n",
      "44\n",
      "root\n",
      " |-- Estacio: integer (nullable = true)\n",
      " |-- nom_cabina: string (nullable = true)\n",
      " |-- codi_dtes: string (nullable = true)\n",
      " |-- zqa: integer (nullable = true)\n",
      " |-- codi_eoi: integer (nullable = true)\n",
      " |-- Longitud: double (nullable = true)\n",
      " |-- Latitud: double (nullable = true)\n",
      " |-- ubicacio: string (nullable = true)\n",
      " |-- Codi_districte: integer (nullable = true)\n",
      " |-- Nom_districte: string (nullable = true)\n",
      " |-- Codi_barri: integer (nullable = true)\n",
      " |-- Nom_barri: string (nullable = true)\n",
      " |-- Clas_1: string (nullable = true)\n",
      " |-- Clas_2: string (nullable = true)\n",
      " |-- Codi_Contaminant: integer (nullable = true)\n",
      "\n",
      "54\n",
      "root\n",
      " |-- Estacio: integer (nullable = true)\n",
      " |-- nom_cabina: string (nullable = true)\n",
      " |-- codi_dtes: string (nullable = true)\n",
      " |-- zqa: integer (nullable = true)\n",
      " |-- codi_eoi: integer (nullable = true)\n",
      " |-- Longitud: double (nullable = true)\n",
      " |-- Latitud: double (nullable = true)\n",
      " |-- ubicacio: string (nullable = true)\n",
      " |-- Codi_districte: integer (nullable = true)\n",
      " |-- Nom_districte: string (nullable = true)\n",
      " |-- Codi_barri: integer (nullable = true)\n",
      " |-- Nom_barri: string (nullable = true)\n",
      " |-- Clas_1: string (nullable = true)\n",
      " |-- Clas_2: string (nullable = true)\n",
      " |-- Codi_Contaminant: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_lookup_airquality_2018 = \"../data/persistent-landing-zone/lookup/2018_qualitat_aire_estacions_49d67292d3b070494d872ad69f21f33606716bb9.avro\"\n",
    "path_lookup_airquality_2019 = \"../data/persistent-landing-zone/lookup/2019_qualitat_aire_estacions_5f9388b444618fc1387c41c37a046654b0108562.avro\"\n",
    "path_lookup_airquality_2021 = \"../data/persistent-landing-zone/lookup/2021_qualitat_aire_estacions_9c3f3f21f8b8971eb9ae125332941562e3563d0c.avro\"\n",
    "path_lookup_airquality_2022 = \"../data/persistent-landing-zone/lookup/2022_qualitat_aire_estacions_e49f11472d56ba08a21890e29a82cc119905671b.avro\"\n",
    "path_lookup_airquality_2023 = \"../data/persistent-landing-zone/lookup/2023_qualitat_aire_estacions_7b02c1ee60564eb060b1874f39f20b085cefc152.avro\"\n",
    "\n",
    "df_2018 = spark.read.format(\"avro\").load(path_lookup_airquality_2018)\n",
    "df_2019 = spark.read.format(\"avro\").load(path_lookup_airquality_2019)\n",
    "df_2021 = spark.read.format(\"avro\").load(path_lookup_airquality_2021)\n",
    "df_2022 = spark.read.format(\"avro\").load(path_lookup_airquality_2022)\n",
    "df_2023 = spark.read.format(\"avro\").load(path_lookup_airquality_2023)\n",
    "\n",
    "for df in [df_2018, df_2019, df_2021, df_2022, df_2023]:\n",
    "    print(df.count())\n",
    "    df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema equality between 2018 and 2019: False\n",
      "Schema equality between 2019 and 2021: True\n",
      "Schema equality between 2021 and 2022: True\n",
      "Schema equality between 2022 and 2023: True\n"
     ]
    }
   ],
   "source": [
    "dfs_with_year = [(2018, df_2018), (2019, df_2019), (2021, df_2021), (2022, df_2022), (2023, df_2023)]\n",
    "# check pairwise schema equality\n",
    "for (year1, df1), (year2, df2) in zip(dfs_with_year, dfs_with_year[1:]):\n",
    "    print(f\"Schema equality between {year1} and {year2}: {df1.schema == df2.schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- nom_cabina: string (nullable = true)\n",
      " |-- codi_dtes: string (nullable = true)\n",
      " |-- zqa: integer (nullable = true)\n",
      " |-- codi_eoi: integer (nullable = true)\n",
      " |-- longitud: double (nullable = true)\n",
      " |-- latitud: double (nullable = true)\n",
      " |-- Ubicacio: string (nullable = true)\n",
      " |-- Codi_Districte: integer (nullable = true)\n",
      " |-- Nom_Districte: string (nullable = true)\n",
      " |-- Codi_Barri: integer (nullable = true)\n",
      " |-- Nom_Barri: string (nullable = true)\n",
      " |-- Ocupacio_sol: string (nullable = true)\n",
      " |-- Emissions_Properes: string (nullable = true)\n",
      " |-- Contaminant_1: string (nullable = true)\n",
      " |-- Contaminant_2: string (nullable = true)\n",
      " |-- Contaminant_3: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_2018.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Estacio: integer (nullable = true)\n",
      " |-- nom_cabina: string (nullable = true)\n",
      " |-- codi_dtes: string (nullable = true)\n",
      " |-- zqa: integer (nullable = true)\n",
      " |-- codi_eoi: integer (nullable = true)\n",
      " |-- Longitud: double (nullable = true)\n",
      " |-- Latitud: double (nullable = true)\n",
      " |-- ubicacio: string (nullable = true)\n",
      " |-- Codi_districte: integer (nullable = true)\n",
      " |-- Nom_districte: string (nullable = true)\n",
      " |-- Codi_barri: integer (nullable = true)\n",
      " |-- Nom_barri: string (nullable = true)\n",
      " |-- Clas_1: string (nullable = true)\n",
      " |-- Clas_2: string (nullable = true)\n",
      " |-- Codi_Contaminant: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_2019.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(nom_cabina='Barcelona - Ciutadella', codi_dtes='IL', zqa=1, codi_eoi=8019050, longitud=2.1874, latitud=41.3864, Ubicacio='Parc de la Ciutadella', Codi_Districte=1, Nom_Districte='Ciutat Vella', Codi_Barri=4, Nom_Barri='Sant Pere, Santa Caterina i la Ribera', Ocupacio_sol='Urbana', Emissions_Properes='Fons', Contaminant_1='NO2', Contaminant_2='O3', Contaminant_3=None),\n",
       " Row(nom_cabina='Barcelona - Eixample', codi_dtes='IH', zqa=1, codi_eoi=8019043, longitud=2.1538, latitud=41.3853, Ubicacio='Av. Roma - c/ Comte Urgell', Codi_Districte=5, Nom_Districte='Eixample', Codi_Barri=9, Nom_Barri=\"la Nova Esquerra de l'Eixample\", Ocupacio_sol='Urbana', Emissions_Properes='TrÃ\\xa0nsit', Contaminant_1='NO2', Contaminant_2='O3', Contaminant_3='PM10'),\n",
       " Row(nom_cabina='Barcelona - GrÃ\\xa0cia', codi_dtes='IJ', zqa=1, codi_eoi=8019044, longitud=2.1534, latitud=41.3987, Ubicacio='PlaÃ§a GalÂ·la PlacÃ\\xaddia (Via Augusta - Travessera de GrÃ\\xa0cia)', Codi_Districte=6, Nom_Districte='Gracia', Codi_Barri=31, Nom_Barri='la Vila de Gracia', Ocupacio_sol='Urbana', Emissions_Properes='TrÃ\\xa0nsit', Contaminant_1='NO2', Contaminant_2='O3', Contaminant_3='PM10'),\n",
       " Row(nom_cabina='Barcelona - Palau Reial', codi_dtes='IZ', zqa=1, codi_eoi=8019057, longitud=2.1151, latitud=41.3875, Ubicacio='c/ John Maynard Keynes - c/ de Jordi Girona', Codi_Districte=4, Nom_Districte='Les Corts', Codi_Barri=21, Nom_Barri='Pedralbes', Ocupacio_sol='Urbana', Emissions_Properes='Fons', Contaminant_1='NO2', Contaminant_2='O3', Contaminant_3='PM10'),\n",
       " Row(nom_cabina='Barcelona - Poblenou', codi_dtes='I2', zqa=1, codi_eoi=8019004, longitud=2.2045, latitud=41.4039, Ubicacio='PlaÃ§a Josep Trueta (Pujades - Lope de Vega)', Codi_Districte=10, Nom_Districte='Sant Marti', Codi_Barri=68, Nom_Barri='el Poblenou', Ocupacio_sol='Urbana', Emissions_Properes='Fons', Contaminant_1='NO2', Contaminant_2=None, Contaminant_3='PM10')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2018.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Estacio=50, nom_cabina='Barcelona - Ciutadella', codi_dtes='IL', zqa=1, codi_eoi=8019050, Longitud=2.1874, Latitud=41.3864, ubicacio='Parc de la Ciutadella', Codi_districte=1, Nom_districte='Ciutat Vella', Codi_barri=4, Nom_barri='Sant Pere, Santa Caterina i la Ribera', Clas_1='Urbana', Clas_2='Fons', Codi_Contaminant=8),\n",
       " Row(Estacio=50, nom_cabina='Barcelona - Ciutadella', codi_dtes='IL', zqa=1, codi_eoi=8019050, Longitud=2.1874, Latitud=41.3864, ubicacio='Parc de la Ciutadella', Codi_districte=1, Nom_districte='Ciutat Vella', Codi_barri=4, Nom_barri='Sant Pere, Santa Caterina i la Ribera', Clas_1='Urbana', Clas_2='Fons', Codi_Contaminant=14),\n",
       " Row(Estacio=50, nom_cabina='Barcelona - Ciutadella', codi_dtes='IL', zqa=1, codi_eoi=8019050, Longitud=2.1874, Latitud=41.3864, ubicacio='Parc de la Ciutadella', Codi_districte=1, Nom_districte='Ciutat Vella', Codi_barri=4, Nom_barri='Sant Pere, Santa Caterina i la Ribera', Clas_1='Urbana', Clas_2='Fons', Codi_Contaminant=7),\n",
       " Row(Estacio=50, nom_cabina='Barcelona - Ciutadella', codi_dtes='IL', zqa=1, codi_eoi=8019050, Longitud=2.1874, Latitud=41.3864, ubicacio='Parc de la Ciutadella', Codi_districte=1, Nom_districte='Ciutat Vella', Codi_barri=4, Nom_barri='Sant Pere, Santa Caterina i la Ribera', Clas_1='Urbana', Clas_2='Fons', Codi_Contaminant=12),\n",
       " Row(Estacio=43, nom_cabina='Barcelona - Eixample', codi_dtes='IH', zqa=1, codi_eoi=8019043, Longitud=2.1538, Latitud=41.3853, ubicacio='Av. Roma - c/ Comte Urgell', Codi_districte=5, Nom_districte='Eixample', Codi_barri=9, Nom_barri=\"la Nova Esquerra de l'Eixample\", Clas_1='Urbana', Clas_2='TrÃ\\xa0nsit', Codi_Contaminant=8)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2019.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ocupacio_sol == Clas_1 and Emissions_Properes == Clas_2\n",
    "\n",
    "Contaminant_1, Contaminant_2, and Contaminant_3 from 2018 not in the rest\n",
    "\n",
    "Codi_Contaminant not in 2018, but in the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if column 'nom_cabina' determines 'Estacio'\n",
    "df_2019.select(\"nom_cabina\", \"Estacio\").distinct().count() == df_2019.select(\"nom_cabina\").distinct().count() and \\\n",
    "df_2019.select(\"nom_cabina\", \"Estacio\").distinct().count() == df_2019.select(\"Estacio\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nom_cabina determines Estacio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
